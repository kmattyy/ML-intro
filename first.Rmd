---
title: "Iris"
author: "Kuti K. Matyas"
date: "1/28/2017"
output: html_document
---

Elsőként az Iris adathalmazt választottam. Programozási nyelvnek pedig az R-t azon belül ay H2O csomagot. Egy picit 'overkill' a feladathoz de hasznosnak találtam kipróbálni mivel munkában osztott rendszeren dolgozunk(Hadoop) és H2O-val lehet HDFS-ben tárolt nagyobb adathalmazokat is feldolgozni(összekötöttem a hasznost a hasznossal). Hátránya is van: kevés modell van implementálva. Például az SVM hiánzyik mivel nehezebben párhuzamositható osztott rendszeren.

Az iris adathalmaz kicsi viszont szerintem egész jól lehet majd mérni az osztályozók pontosságát mivel az egyik osztály elválasztható a másik 2től lineárisan, de az utóbbi 2 nem szétválasztható.(lásd alábbi ábra 3 változóval)


```{r,message=FALSE,warning=FALSE}
library(plotly)
plot_ly(iris,x=~Petal.Length,y=~Sepal.Length, z=~Petal.Width, color = ~Species, type="scatter3d",marker = list(opacity=0.5))
```


##Az adatok
Csupán 4 valós változó van a virágok szirmainak méréseivel valamint a virág tipusa. Előfeldolgozást sem igényel az adathalmaz. A tipus átalakitható "one hot encoding" modszerrel ha éppenséggel valamelyik mérést szeretnénk becsülni a többi  paraméter alapján. Az adathalmaz az R környezet része, nem volt szükség letölteni.


```{r,message=FALSE,warning=FALSE}
library(h2o)
h2o.init(nthreads = 8) #kapcsolódni-elinditani a szervert
irisdf <-as.h2o(iris) #betolteni az adatokat  a 'szerverbe'
summary(irisdf)
isplit<-h2o.splitFrame(irisdf,ratios = .8, destination_frames = c("train","test"),seed =121) #felosztas
itrain <- isplit[[1]]
itest <- isplit[[2]]
summary(itrain)
summary(itest)
```
A split nem tökéletesen arányos mivel nagy adathalmazokra van kitalálva és arra megfeleloen mukodik.

Készitetek egy normalizált adathalmazt is az eredménzek összehasonlitása érdekében.

```{r}
library(clusterSim) #normalizalashoz hasznalt csomag
iris_norm <- iris
iris_norm$Sepal.Length <-data.Normalization(iris_norm$Sepal.Length,type = 'n12') # n12 = ((x-mean)/sqrt(sum((x-mean)^2))) 
iris_norm$Sepal.Width <-data.Normalization(iris_norm$Sepal.Width,type = 'n12')
iris_norm$Petal.Length <-data.Normalization(iris_norm$Petal.Length,type = 'n12')
iris_norm$Petal.Width <-data.Normalization(iris_norm$Petal.Width,type = 'n12')
irisnormdf <-as.h2o(iris_norm)
isplit<-h2o.splitFrame(irisnormdf,ratios = .8, destination_frames = c("train","test"),seed =121) #felosztas
intrain <- isplit[[1]]
intest <- isplit[[2]]
summary(intrain)
summary(intest)
plot_ly(iris_norm,x=~Petal.Length,y=~Sepal.Length, z=~Petal.Width, color = ~Species, type="scatter3d",marker = list(opacity=0.5))
```


##Az osztályozók
A 3 osztályozó amit választottam: Naive Bayes, Neuralis háló és Random forest .


####Bayes
```{r}
bayes <- h2o.naiveBayes(x=1:4,y=5,itrain)
bayes@model$training_metrics
bayes@model$apriori
bayes@model$pcond
perfbayes <- h2o.performance(bayes,itest)
h2o.confusionMatrix(perfbayes)
```
####Neuralis halo
```{r}
nn <- h2o.deeplearning(x=1:4,y=5,itrain,hidden = c(10),epochs = 1000,diagnostics=TRUE,variable_importances = TRUE,export_weights_and_biases=TRUE,standardize = FALSE) #egy 10es rejtett reteg
nn@model$training_metrics
nn@model$model_summary
h2o.varimp_plot(nn)
h2o.weights(nn,matrix_id = 1)
h2o.biases(nn,vector_id = 1)
perfnn <- h2o.performance(nn,itest)
h2o.confusionMatrix(perfnn)

```

####Random forest
```{r,message=FALSE}
rf <- h2o.randomForest(x=1:4,y=5,itrain, ntrees = 40) #20 fabol allo RF
rf@model$training_metrics
rf@model$model_summary
h2o.varimp_plot(rf)
perfrf <- h2o.performance(rf,itest)
h2o.confusionMatrix(perfrf)
```



```{r}
gendata <- function(n,params){
  sl1 <- params[[1]][1,] #s-sepal,p-petal l-lenght w-width 1-setosa
  sw1 <- params[[2]][1,]
  pl1 <- params[[3]][1,]
  pw1 <- params[[4]][1,]
  dfsetosa<-cbind(rnorm(n=n,mean = sl1["mean"]$mean,sd = sl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = sw1["mean"]$mean,sd = sw1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pl1["mean"]$mean,sd = pl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pw1["mean"]$mean,sd = pw1["std_dev"]$std_dev),
                  rep("setosa",times=n))
  dfsetosa <- as.data.frame(dfsetosa)
  names(dfsetosa)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
  
  sl1 <- params[[1]][2,] #2-versicolor
  sw1 <- params[[2]][2,]
  pl1 <- params[[3]][2,]
  pw1 <- params[[4]][2,]
  dfversicolor<-cbind(rnorm(n=n,mean = sl1["mean"]$mean,sd = sl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = sw1["mean"]$mean,sd = sw1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pl1["mean"]$mean,sd = pl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pw1["mean"]$mean,sd = pw1["std_dev"]$std_dev),
                  rep("versicolor",times=n))
  dfversicolor<- as.data.frame(dfversicolor)
  names(dfversicolor)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
  
  sl1 <- params[[1]][3,] #3-virginica
  sw1 <- params[[2]][3,]
  pl1 <- params[[3]][3,]
  pw1 <- params[[4]][3,]
  dfvirginica<-cbind(rnorm(n=n,mean = sl1["mean"]$mean,sd = sl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = sw1["mean"]$mean,sd = sw1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pl1["mean"]$mean,sd = pl1["std_dev"]$std_dev),
                  rnorm(n=n,mean = pw1["mean"]$mean,sd = pw1["std_dev"]$std_dev),
                  rep("virginica",times=n))
  dfvirginica<- as.data.frame(dfvirginica)
  names(dfvirginica)<-c("Sepal.Length","Sepal.Width","Petal.Length","Petal.Width","Species")
  
  
  rbind(dfsetosa,dfversicolor,dfvirginica,stringsAsFactors=FALSE)
}

testd <- gendata(n=200,bayes@model$pcond) 
testd$Sepal.Length <- as.double(as.character(testd$Sepal.Length))
testd$Petal.Length <- as.double(as.character(testd$Petal.Length))
testd$Sepal.Width <- as.double(as.character(testd$Sepal.Width))
testd$Petal.Width <- as.double(as.character(testd$Petal.Width))
plot_ly(testd,x=~Petal.Length,y=~Sepal.Length, z=~Petal.Width, color = ~Species,marker = list(opacity=0.5))
td<-as.h2o(testd)
h2o.performance(nn,td)
h2o.performance(bayes,td)
h2o.performance(rf,td)
testd<-cbind(testd,as.data.frame(h2o.predict(nn,td)))
testd$val <- ifelse(testd$Species == testd$predict,"+","-")
plot_ly(testd,x=~Petal.Length,y=~Sepal.Length, z=~Petal.Width, color = ~val,colors=c("red","green"),marker = list(opacity=0.2),text=~paste(Species," ",predict))
```

```{r}
nn <- h2o.deeplearning(x=2:4,y=5,irisdf,hidden = c(10),epochs = 1000,diagnostics=TRUE,variable_importances = TRUE,export_weights_and_biases=TRUE) 
nn@model$training_metrics
#nn@model$model_summary
h2o.varimp_plot(nn)
nn@model$variable_importances
```

```{r}
rf <- h2o.randomForest(x=1:4,y=5,itrain, ntrees = 200) 
rf@model$training_metrics
rf@model$model_summary
h2o.varimp_plot(rf)
```



```{r}
x <- seq(0,8,by=0.1)
y <- seq(0,7,by=0.1)
z <- seq(0,3,by=0.1)
gr<-expand.grid(Sepal.Length=x,Petal.Length=y,Petal.Width=z)
grid<-as.h2o(gr,destination_frame = "grid")
prrf<-as.data.frame(h2o.predict(rf,grid))
prnn<-as.data.frame(h2o.predict(nn,grid))


```



```{r,message=FALSE,warning=FALSE}
plot_ly(gr,x=~Petal.Length,y=~Sepal.Length, z=~Petal.Width, color = prrf$predict,marker = list(opacity=0.2))
```



